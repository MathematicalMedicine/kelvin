<h1>Polynomial Compilation</h1>
<h2>How Does kelvin use Polynomials?</h2>
In order to understand the value of polynomial compilation, one must first understand how kelvin uses
polynomials.
<p>
When kelvin performs an analysis, it is calculating the likelihood of of every pedigree's structure
and characteristics for each combination of values in the trait model space, which is normally a range of 
6 gene frequencies, 275 penetrances, and 20 alpha values, or 33,000 combinations of values. This is repeated for
each trait position or combination of trait and markers in the analysis.
<p>
In (original) non-polynomial mode, the pedigree likelihood is explicitly calculated for each combinations of 
trait model values via a series of tests, loops and calculations built-into kelvin. 
Since these tests, loops and calculations are all hard-coded in the program, they cannot be 
optimized or simplified in any way in response to the nature of underlying pedigree, so the same full path is followed
for every combination of values. If the first set of values takes a minute to process, we know that the entire
analysis is going to take tens of thousands or millions of minutes.
<p>
In polynomial mode, we go thru this same hard-coded path in kelvin one time building a symbolic representation of the
calculation using place-holder variables from the trait model space instead of explicit values. In effect, we
build a polynomial that encodes the structure and characteristics of the pedigree in terms of the variables from
the trait model space. This polynomial is then extensively optimized using mathematical and computational
techniques so that when we substitute-in trait model space values and evaluate it, it performs the calculation 
orders of magnitude faster than the original hard-coded path in kelvin.

<h2>
During a polynomial-mode  analysis, a separate likelihood polynomial is built for each pedigree and combination of
relative trait/marker positions. For example, a multipoint analysis with
two pedigrees and three markers where evaluated trait positions occur between every marker pair as well as before
and after all markers would generate eight polynomials:
<ul>
<li>pedigree 1 for trait/marker pattern T-M1-M2-M3
<li>pedigree 2 for trait/marker pattern T-M1-M2-M3
<li>pedigree 1 for trait/marker pattern M1-T-M2-M3
<li>pedigree 2 for trait/marker pattern M1-T-M2-M3
<li>pedigree 1 for trait/marker pattern M1-M2-T-M3
<li>pedigree 2 for trait/marker pattern M1-M2-T-M3
<li>pedigree 1 for trait/marker pattern M1-M2-M3-T
<li>pedigree 2 for trait/marker pattern M1-M2-M3-T
</ul>
<p>
<h2>How Compilation Works</h2>
Polynomial compilation is a method of post-processing the in-memory polynomials generated by kelvin
so as to facilitate rapid evaluation and reuse.
<p>
Polynomials are built in-memory as usual, and then translated into C-language code and written to one or
more source files which are then compiled into dynamic libraries. These dynamic libraries are
reusable compiled representations of the original polynomials that can be
loaded on-demand and evaluated up to ten times faster than their in-memory counterparts. Once
a dynamic library is built for a given polynomial, the relatively slow and memory-intensive process of generating
that polynomial need not be performed again. 

<h2>Phases in Polynomial Compilation</h2>
Polynomial compilation consists of three phases that have very different requirements and optimization
possibilities:
<ol>
<li><b>Polynomial build and code generation.</b> This is the normal process of polynomial building that occurs whenever
you use the <tt>PE</tt> directive in your analysis, coupled with the fairly quick additional 
step of generating a number of <tt>C</tt>-code files to represent the polynomial. As with the normal polynomial
build process, this step can be very memory-intensive depending upon the structure of the pedigrees and number 
of positions in the analysis, and does not benefit significantly from running in
a multi-threaded environment.
<li><b>Code compilation and dynamic library (DL) linking.</b>
Compilation can be performed at the time the source is generated by kelvin itself,
or by way of batch jobs submitted on multiple
nodes. These two approaches are incompatible because if kelvin is doing the compiling, it expects that when
it gets done there will be a ready-to-load dynamic library. This will not be the case if the compilation is
being distributed to multiple nodes via batch jobs. There are, therefore, two ways to go:
<ol>
<li> Run kelvin-POLYCOMP_DL, which will generate, compile, link and use dynamic libraries all by itself, or
<li> Use a multi-step approach:
<ol>
<li>Run kelvin-POLYCODE_DL-FAKEEVALUATE, which will generate the code for dynamic libraries, but neither
compile nor try to load and use them. This is platform-independent, possibly memory-intensive, and single-
threaded.
<li>Compile (and ultimately link) all of the source files generated. This can be done on any 
linux nodes that are hardware-compatible
with the platform to be used in the evaluation step. It can be performed thoroughly in parallel, and even
started while the previous step is still running so long as polynomial code is available to compile.
<li>Run kelvin-POLYUSE_DL. Once all generated polynomials are compiled and linked, kelvin-POLYUSE_DL will be
able to load and use them instead of generating the polynomials. This step uses only a fraction
(generally a third or less) of the memory required to hold a normal polynomial, and allows rapid, multi-
threaded evaluation of the separate pedigree polynomials for each position.
</ol>
</ol>

<h2>When to Use Polynomial Compilation</h2>
Generally, you should use polynomial compilation only when it is feasible in your computational environment and
the cost and complexity of compiling and linking dynamic libraries is exceeded by the benefits of rapid
and repeatable evaluation.
<h3>Indications</h3>
<ul>
<li>When the ratio of evaluations to trait/marker position changes is high. This is an indication to use
polynomial evaluation in general, and compilation in particular.
<li>When the run-time of an evalution is prohibitive. Compilation can reduce evaluation time by up to an
order of magnitude.
<li>When the same set of markers will be used with varying sets of pedigrees in multiple analyses. Since named
polynomials are specific to pedigree and trait/marker position, analyses that consider various subsets of a group
of pedigrees pay the price of compilation only once for each pedigree and trait/marker position, and then reuse
them without additional cost.
</ul>
<h3>Counterindications</h3>
<li>When pedigrees are very simple.
<li>When only a single evaluation will be performed.
</ul>
