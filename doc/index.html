<html>
<head><title>kelvin ReadMe</title></head>
<body>
<h1>kelvin ReadMe</h1>
<h2>INTRODUCTION</h2>
kelvin is an ANSI C implementation of the Elston-Stewart algorithm for linkage
analysis. It currently supports two-point and multipoint analyses, dichotomous and
quantitative traits, linkage equilibrium and disequilibrium, case control, and many
other options. It is copyright 2008, Nationwide Children's Research Institute. All
rights reserved. Permission is hereby given to use this software for non-profit
educational purposes only. Please address any e-mail regarding kelvin to
<a href="mailto:kelvin@nationwidechildrens.org">kelvin@nationwidechildrens.org</a>.
<h2>BUILDING THE PROGRAMS</h2>
<h3>Requirements</h3>
<h4>Platforms</h4>
kelvin is written in ANSI C, with some supporting scripts in Perl.
kelvin releases are currently tested on the following platforms:
<ul>
<li>Redhat Enterprise Linux x86_64 with GCC 4.1.1
<li>Debian Linux i386 with GCC 4.1.1
<li>Macintosh OSX 10.4 i386 with GCC 4.0.1 (no OpenMP) and GCC 4.3.0
<li>Macintosh OSX 10.4 PowerMac with GCC 4.0.1 (no OpenMP)
<li>Cygwin under Windows XP i386 with GCC 3.4.4 (cygming special)
</ul>
We don't know of any reason why kelvin shouldn't run on any platform supported by GNU CC and the GNU Scientific
Library, so if you encounter incompatabilities, please let us know.

<h4>Libraries</h4>
kelvin currently only requires the <a href="http://www.gnu.org/software/gsl/">GNU Scientific Library</a>
(GSL), a free numerical library for C and C++. You will want to make a note of the location of the library and include
files on your system so that you can modify the kelvin Makefile if necessary.
<p>
When kelvin is run in polynomial mode, it makes very extensive use of memory management, and can, under most
circumstances, definitely benefit from a drop-in allocator such as <a href="http://www.hoard.org/">hoard</a>
or <a href="http://www.malloc.de/en/">ptmalloc3</a>. Either of these can easily halve execution time, and will
keep memory fragmentation down when running in mult-threaded mode, but they are not required. For more
details on using drop-in allocators with kelvin, see <a href="Allocators.html">the allocators section</a>.

<h4>Resources</h4>
kelvin's resource requirements vary wildly depending upon the complexity of the analysis
being performed. In general, the memory requirements are negligible unless you use polynomial
mode (PE in the configuration file) to speed-up calculations. The idea of speeding-up calculations can become
quite attractive, as some seemingly simple analyses involve millions of iterations and
take literally months to run.
Polynomial mode can reduce
runtime by several orders of magnitude, but can also easily exceed 16Gb of memory for
complex pedigrees or those with untyped founders. The best approach is to normally use
polynomial mode, and fall back to non-polynomial mode if memory becomes an issue. Recent releases of kelvin
monitor CPU and memory utilization and will self-terminate if thrashing memory.
<p>
If you are running on a mult-core platform, and your compiler supports OpenMP 2.0, you can build kelvin
to use multiple threads and reduce your single-analysis runtime significantly at a marginal increase in memory, less if
you use a drop-in allocator as described above.
<h3>Installation</h3>
kelvin is developed in a Linux environment, so standard unix tools are used for build management and
distribution.
kelvin is currently distributed as a compressed tarball of the directory hierarchy of our
latest release, e.g. <tt>kelvin-0.34.2.tar.gz</tt>.
<h4>Directory Structure and Components</h4>
<ul>
<li><tt>&lt;RELEASE&gt;/</tt> - kelvin, dkelvin and calc_updated_ppl components. Includes normal and debug versions of the master Makefile.
kelvin is the primary linkage analysis program and the focus of this documentation. dkelvin is a variant that
uses a multidimensional integration approach to analysis, and is still under development. calc_updated_ppl is
a tool for combining the results of an analysis broken into separate kelvin runs.
<li><tt>&lt;RELEASE&gt;/doc/</tt> - (very) limited documentation.
<li><tt>&lt;RELEASE&gt;include/</tt> - a work directory for builds.
<li><tt>&lt;RELEASE&gt;/lib/</tt> - a work directory for builds.
<li><tt>&lt;RELEASE&gt;pedlib/</tt> - pedigree, likelihood, and polynomial components. Includes a dependent Makefile - don't try
to use it by itself.
<li><tt>&lt;RELEASE&gt;/seq_update/</tt> - routines to perform a sequential update of the average likelihood ratios of separate
kelvin runs.
<li><tt>&lt;RELEASE&gt;/test-suite/</tt> - analyses that can be used for build validation as well as configuration examples.
<li><tt>&lt;RELEASE&gt;/utils/</tt> - general-purpose utility components. Includes a dependent Makefile.
</ul>
<h4>Building and Testing</h4>
Edit the master Makefile to specify the location of the gsl libraries and include files on your system.
If you do not have an OpenMP-capable compiler, comment-out the lines that reference "-fopenmp" as indicated
in the Makefile comments. Type <kbd>make clean</kbd> and then <kbd>make</kbd>.
This should build supporting libraries and then the three executable images kelvin, dkelvin and calc_updated_ppl. 
Next, type <kbd>make test</kbd> to run a suite of tests.
If you should see errors during the build or test, or run into other problems with kelvin,
please send us a log of the build and test. Finally, type <kbd>make install</kbd> to move
the executable components into production. 

<h2>PREPARING YOUR CONFIGURATION FILE</h2>
kelvin takes all of its configuration information from a single file specified on the command line.
This file is composed of directives that describe the analysis to be performed, and the locations
of supporting data files.
Extensive information on the directives used in the kelvin configuration file is provided in <tt>doc/ReadMe.conf</tt>.
It is the final authority on the behavior of the directives, and the only source of information on the
specification of
parameters and ranges. A <a href="Directives.html">rewrite</a> of that document is in-progress.
<p>
kelvin provides such a wide variety of options for linkage analysis that it can be confusing to
determine what combinations of directives are appropriate. <a href="config.gif">This chart</a>
illustrates the twenty-two current configuration "paths" for kelvin, and the directives they use. Ellipses
represent defaults that will be taken in the absence of relevant directives, while squares represent
analysis attributes that must always be explicity specified.
<p>
The distribution includes subdirectories with sample configuration files for a few of
the configuration "paths". We typically name the configuration files <tt>kelvin.conf</tt>.
These illustrate the required configuration information, and can serve as starting points for your own
versions. Unless otherwise noted, we have externally verified the results of analysis for these tests,
and they are provided in each directory in <tt>avghet.out-baseline</tt> and (as appropriate) 
<tt>ppl.out-baseline</tt>. The runtimes
listed are on an Macintosh OSX 10.4 i386 with GCC 4.0.1 (no OpenMP).
<ul>
<li>Two-point analysis of a dichotomous trait: <tt>&lt;RELEASE&gt;/test-suite/TP_DT_LE/</tt>, runs in 50s.
<li>Two-point analysis of a dichotomous trait with linkage disequilibrium: <tt>&lt;RELEASE&gt;/test-suite/TP_DT_LD/</tt>, runs in 1m 23s.
<li>Two-point analysis of a dichotomous trait going marker-to-marker: <tt>&lt;RELEASE&gt;/test-suite/TP_DT_MM_LE/</tt>, runs in less than 1s.
<li>Two-point analysis of a dichotomous trait going marker-to-marker with linkage disequilibrium: <tt>&lt;RELEASE&gt;/test-suite/TP_DT_MM_LD/</tt>, runs in less than 1s.
<li>Two-point analysis of a quantitative trait: <tt>&lt;RELEASE&gt;/test-suite/TP_QT_LE/</tt>, runs in 27s.
<li>Multipoint analysis of a dichotomous trait: <tt>&lt;RELEASE&gt;/test-suite/MP_DT/</tt>, runs in 2s.
<li>Multipoint analysis of a quantitative trait: <tt>&lt;RELEASE&gt;/test-suite/MP_QT/</tt>, runs in 1s.
</ul>

<h2>RUNNING THE PROGRAMS</h2>
Once you have installed kelvin, you can run it from your data directory, where you keep your
configuration and data files. kelvin takes only one parameter, which is the name of the
configuration file, e.g.:

<pre>
_$ kelvin kelvin.conf
</pre>
Remember that if you did not specify absolute paths for output files in the configuration file, they
will be written to your current directory.
<p>
It is often convenient to capture all output from a run into a file so that you may review it more
conveniently, or send it to us for diagnosis. The following command (using bash shell syntax)
runs kelvin with all output
redirected to a file called <tt>kelvin.out</tt>:
<pre>
_$ kelvin kelvin.conf >& kelvin.out
</pre>
If you do need to send us information for diagnosis, please include the configuration and data files
along with the output from the run.
<h3>Diagnostic Messages</h3>
When kelvin or dkelvin are run, they first display version, build and run configuration information, e.g.:
<pre>
PID: 3072, kelvin V0.34.2 built May 29 2008 10:06:56
PID: 3072, Id: kelvin.c 579 2008-06-03 13:28:20Z whv001
PID: 3072, Id: likelihood.c 533 2008-05-23 17:26:34Z whv001
PID: 3072, Id: locus.c 471 2008-05-06 20:17:17Z whv001
PID: 3072, Id: polynomial.c 570 2008-06-02 19:28:31Z whv001
PID: 3072, Compiler 4.1.1 20070105 (Red Hat 4.1.1-52), GSL 1.9
PID: 3072, OpenMP-enabled w/0 threads.
To force a dump of stats (at some risk), type CTRL-\ or type "kill -3 3072".
PID: 3072, In /Users/whv001/kelvin/trunk/test-suite/MP_DT w/kelvin.conf
polynomialScale is 1 (1-10, 1 is default)
PID: 3072, Computation is done in polynomial mode

</pre>
The first line is the kelvin major version and build information, and the subsequent lines
that contain "Id:" are source-managed component version information. Next is the compiler
and GNU Scientific Library verison numbers. Lines after that
describe important build options as specified in the Makefile and run
characteristics as influenced by environment variables.
<p>
In the midst of this is a line describing the action to take in order to force a dump of a line of
statistics. The format of these statistics is described at the end of this section (<a href="#adhoc">ad hoc status</a>).
You can use this as a sort of "pulse check" to make sure kelvin is still alive
and well and making progress should there be a lull between automatic progress updates. If
you are running kelvin interactively, you can type <tt>CTRL-\</tt> (that means to hold down the CTRL
or CONTROL key while pressing the backslash). If you are running under cygwin, you will need to
type <tt>stty quit ^C</tt> first for this to work. Strangely enough, that <tt>^C</tt> is the two
character sequence of 'carat' (shifted 6) and 'C'. This sends a SIGQUIT signal to kelvin, which it
interprets as a request for status. If you are running kelvin as a detached
process or in a queue, you can send a SIGQUIT to the process using the <tt>kill</tt> command
as described in the diagnostic output. Note that the signal number (-3 in the example) can be
different from platform-to-platform, and the
process ID (3072 in the example) will be different from run-to-run.
<p>
Next, the analysis characteristics as determined from the configuration and data files
are displayed, e.g.:
<pre>
Trait-to-marker, Sex-Averaged Multipoint, Dichotomous Trait.
</pre>
Finally, progress indicators are displayed up through the end of the run.

<h3>Monitoring Progress</h3>
There are two levels of detail of progress information for you to choose from. The default is to simply display
a rough percentage of work completed and a wobbly estimate of how many minutes of work remain. These
numbers can become extremely rough and wobbly in polynomial evaluation mode, because few aspects of the complex operations
they must consider can be accurately estimated, even while they're in-progress. Progress reporting will be most
accurate and useful when you are doing many evaluations of simple pedigrees.
<p>
You need not take any special action in order for progress to be displayed in this manner:
<pre>
Calculations 18% complete (~15 min left)
</pre>
While the simple progress display incorporates trait and marker calculations in its estimations, it doesn't report
progress while they're being performed, so there might be a significant delay before seeing the first non-zero percentage for complex
analyses.
<p>
The alternative level of complexity is much more informative, but can overwhelm with details under certain
circumstances. You will need to edit the <tt>Makefile</tt> to enable the compile-time conditional
<tt>DETAILEDPROGRESS</tt>, and rebuild kelvin (<tt>make clean</tt> and <tt>make</tt>) to turn it on. When it is enabled, kelvin displays
detailed information about each of the steps it goes thru to perform an analysis. These steps are
fundamentally different for Two-Point and Multipoint analyses.

<h4>Detailed Multipoint</h4>
<ol>
<li>Trait likelihood determination progress in percentage until completion. This is only done once
at the beginning of an analysis, so it will proceed to 100%. This is the simplest and therefore fastest
calculation. If this step takes a lot of time, your patience will be sorely tried by subsequent steps:
<pre>
Determining trait likelihood...
Building polynomial w/pedigree: 87 (11/11)
Trait likelihood evaluations 100% complete
</pre>
<li>For each trait position:
<ol>
<li>The new trait position, and the markers to be used in this step of the analysis along with their positions if they are new:
<pre>
Starting w/trait locus at 0.00 (1/8 positions) with new markers 1(0.00) 2(0.64)
Determining marker set likelihood...
</pre>
<li>Likelihood polynomial build progress for new markers. This is shown as progress thru the set of
pedigrees, and is a function of the pedigree complexity and number of markers in the analysis. 
This cannot be reliably estimated at this time, but is typically one of the less time-consuming steps:
<pre>
Building polynomial w/pedigree: 77 (1/11)
</pre>
<li>Marker likelihood evaluation progress for new markers. This is displayed as an incrementing percentage 
until it is interrupted by the completion of the current position. At completion of a position it will reflect 
overall percentage progress of marker likelihood evaluation thru all positions. This may jump because 
we skip marker likelihood evaluation when the marker set does not change in relation to the trait position:
<pre>
Marker set likelihood evaluations 12% complete.
Determining combined likelihood...
</pre>
<li>Combined likelihood polynomial build progress. This is shown as progress thru the set of pedigrees. This is
the most memory-intensive step, and can be very time-consuming as well. Unfortunately, it is nearly completely unpredictable
across trait positions, as it is a function of phenotypic and genotypic constraints for the trait and markers thru
the pedigrees. If your analysis is going to fail due to lack of memory, it will be here. You can anticipate problem 
pedigrees by noting those that took longer than average during
the marker set likelihood polynomial build phase. Accurate estimation would almost require performing the analysis before performing the analysis.
The good news is that evaluation is radically improved by having the polynomial, so if you are analyzing a grid of
penetrances, disease gene frequencies and alpha values, polynomial mode will be much faster.
<pre>
Building polynomial w/pedigree: 87 (11/11)
</pre>
<li>Combined likelihood evaluation progress. This is displays every minute until completion for this position. Note
that the estimation of time remaining can oscillate significantly, so don't use it as a timer when you're baking cookies.
<pre>
Combined likelihood evaluations 1% complete (~83 minutes left)
</pre>
</ol>
</ol>
If polynomial evaluation is not enabled, the progress reports involving polynomials are not displayed.
<h4>Detailed Two-point</h4>
<h4 id="adhoc">Final (and Ad Hoc) Status</h4>
Under either level of complexity, a line of statistics will be displayed at the end of the run that looks
something like this:
<pre>
PID: 3072, stopwatch overall(1) e:462s u:460s s:1s, vx:0, ivx:0, sf:0, hf:0
</pre>
This is a dump of the current values of a virtual stopwatch that was started at the beginning of the analysis.
Of greatest interest are the elapsed time in seconds (<tt>e:462</tt> in the example) and the user CPU time used in seconds
(<tt>u:460</tt>), which can be lower or higher than the elapsed time depending upon if kelvin is competing with
other processes for CPU time or if it is efficiently using multiple threads. The system CPU time (<tt>s:1s</tt>) is also
provided along with some other statistics (voluntary context switches, involuntary context switches, soft faults
and hard faults) that may or may not be available on your platform.
<h4>Additional Options</h4>
There are a number of additional progress reports that can be monitored during a run using compile-time
conditionals. You will need to edit the <tt>Makefile</tt> and rebuild kelvin (<tt>make clean</tt> and <tt>make</tt>) to turn them on
or off:
<ol>
<li><tt>MEMSTATUS</tt> conditional - When kelvin or dkelvin are run on compatible platforms (currently only those with a pmap command),
a child process is created that monitors elapsed time and memory utilization, and displays it every 30 seconds.
<li><tt>POLYSTATISTICS</tt> conditional - If polynomial evaluation is enabled:
<ul>
<li>a count of evaluations peformed thus-far is displayed every 64K evaluations.
<li>extensive statistics on the polynomial build process are displayed
every 2M polynomial creations, when polynomial builds finish, and at the end of the run. Statistics will
include an estimation of internal memory usage when feasible and relevant.
</ul>
</ol>
<h2>INTERPRETING THE RESULTS</h2>
kelvin produces one or two different files of results depending upon the type of analysis performed. 
<h3>Bayes Ratio File</h3>
Integrated likelihood ratio information is produced for all runs. It is written to the file specified by
the <tt>HE</tt> directive, or <tt>br.out</tt> by default.
The first line written to the file is a comment that contains the kelvin version number, e.g.:
<pre>
# kelvin V0.34.2 built May 29 2008 10:06:56
</pre>
This is included so that results can be associated with the version of kelvin that
produced them, and will allow for variations in algorithms, file formats and data precision.
Subsequent lines contain different information for each type of analysis being performed:
<h4>Multipoint Analysis</h4>
For multipoint runs, a single table with a header line is output. The table consists of
one row of whitespace-delimited values for each position in the analysis:
<ol>
<li>Chr - chromosome number
<li>Position - trait position in centiMorgans.
<li>PPL - the imputed posterior probability of linkage.
<li>BayesRatio - average likelihood ratio.
<li>MOD - maximum LOD score achieved at this position.
<li>Alpha - the maximizing alpha, i.e. the value of alpha that maximized the LOD score.
<li>DGF - the maximizing disease gene frequency, i.e. the frequency that maximized the LOD score.
<li>PenetranceVector - penetrance vector. For dichotomous trait runs, it is three (or four) columns of 
the maximizing penetrance for
DD, Dd, (optionally dD,) and dd, i.e. the penetrance that maximized the LOD score.
For quantitative trait runs, it is three (or four) columns of means followed by three (or four) of standard deviations for
the maximizing distributions for DD, Dd, (optionally dD,) and dd, followed by the threshold.
<li>MarkerList - parenthesised list of the closest N markers for each position, where N is the number
of markers being considered at a time.
</ol>
<h4>Two-point Analysis</h4>
Two-point analyses output separate tables for each pair of adjacent loci. For marker-to-marker runs,
this is each pair of adjacent markers. For normal runs, this is the disease locus with each marker.
Each table is prefaced with a comment line that specifies the two loci of interest, e.g.:
<pre>
# 2  Loci_1 at (location) Loci_3 at (location)
</pre>
and consists of one row of whitespace-delimited values for each value of theta:
<ol>
<li>multiple columns of D<i>nm</i> - the D' (d-prime) between allele <i>m</i> of the first locus and allele <i>n</i> of the
second locus. There will be (<i>n</i>-1)*(<i>m</i>-1) columns present for linkage disequilibrium runs. These
columns are not present on LE runs because
LE is a special case of LD where D' is always 0.
<li>Chr - chromosome number
<li>Theta(M,F) - male and female theta values. They are identical for a sex-averaged analysis.
<li>BayesRatio - average likelihood ratio.
<li>MOD - maximum LOD score achieved for this value of theta.
<li>R2 - R square, a measurement of LD.
<li>Alpha - the maximizing alpha, i.e. the value of alpha that maximized the LOD score.
<li>DGF - the maximizing disease gene frequency, i.e. the frequency that maximized the LOD score.
<li>MF - marker allele frequency for the first marker.
<li>PenetranceVector - maximizing penetrance values for DD, Dd, (optionally dD,) and dd.
There will be one set of these for each liability class in the analysis.
</ol>
<h3>Posterior Probability of Linkage File</h3>
Separate PPL information is only produced for two-point analyses, because PPL is imputed for multipoint runs.
It is written to the file specified by the <tt>PF</tt> directive, or <tt>ppl.out</tt> by default.
The first line is a comment that contains the kelvin version number as with the Bayes Ratio file.
The next line is a header, followed by
one line of whitespace-delimited values for each marker in the run.
<ol>
<li>Chr - chromosome number
<li>Marker - marker name
<li>Position - position in centiMorgans
<li>PPL - posterior probability of linkage to the disease locus. PPLs of 2.5% or greater are rounded to
the nearest whole percentage point.
<li>LD-PPL (only for LD analyses)
<li>PPLD (only for LD analyses)
</ol>
<h2>SEQUENTIAL UPDATING</h2>
Sequential updating is a method for combining the results of mutiple analyses in post-processing.
Two tools are provided for performing sequential updating. Both tools expect kelvin average
heterogeneity files as input.

<h3>seq_update_avghet.pl</h3>

This perl script will perform sequential updates on either two-point (the default) or multipoint
files (with <tt>-m multipoint</tt> specified). The script will attempt to determine which columns
contain what data based on column headers. This feature should work with output from recent
versions of kelvin. The script will generate output that resembles the input, but will fill 
non-relevant columns with zeros. There may be fewer output columns than input columns, but
relevant columns (cM position, D', theta, PPL, Bayes ratio) should be present. Multiple
input files may be specified on the command line. In two-point mode, all files should 
contain information for the same markers, in the same order. If <tt>--relax</tt> is specified,
marker name checking will be skipped, but there should still be the same number of markers
in each file. In multi-point mode, there should be information for the same number of
positions in every file. In multi-point mode only, the new PPL will be calculated directly,
based on the updated Bayes ratios. Output is always to the terminal. Here's an example, that
captures the output to a file:

<pre>
_$ seq_update_avghet.pl avghet-1.out avghet-2.out avghet-3.out > updated-avghet.out
</pre>

A full description of command line syntax is available by typing:

<pre>
_$ seq_update_avghet.pl --help
</pre>

<h3>calc_updated_ppl</h3>

This program will calculate PPL, LD-PPL and PPL scores based on a two-point kelvin average
heterogeneity file, or the output from seq_update_avghet.pl. It handles multi-allele (multiple
D's) and sex-specific thetas. It takes only one argument, the name of the input file. Output
is alway to the terminal. Here's an example that, again, captures the output to a file:

<pre>
_$ calc_updated_ppl updated-avghet.out > updated-ppl.out
</pre>
<hr>
$Date$
</body>

</html>
