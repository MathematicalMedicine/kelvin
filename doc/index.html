<html>
<head><title>kelvin ReadMe</title></head>
<body>
<h1>kelvin ReadMe</h1>
<h2>INTRODUCTION</h2>
kelvin is an ANSI C implementation of the Elston-Stewart algorithm for genetic
analysis. It currently supports two-point and multipoint linkage analyses, dichotomous and
quantitative traits, linkage equilibrium and disequilibrium (two-point only), case control data, and many
other options. It uses the well-established  <a href="http://linkage.rockefeller.edu">
LINKAGE (FASTLINK)</a> file formats for pedigree and marker data.
It is copyright 2008, Nationwide Children's Research Institute. All
rights reserved. Permission is hereby given to use this software for non-profit
educational purposes only. Please address any e-mail regarding kelvin to
<a href="mailto:kelvin@nationwidechildrens.org">kelvin@nationwidechildrens.org</a>.
<p>
<h2>INSTALLING THE PROGRAMS</h2>
<h3>Requirements</h3>
<h4>Platforms</h4>
kelvin is written in ANSI C, with some supporting scripts in Perl.
kelvin releases are currently tested on the following platforms:
<ul>
<li>Redhat Enterprise Linux x86_64 with GCC 4.1.1
<li>Debian Linux i386 with GCC 4.1.1
<li>Macintosh OSX 10.4 i386 with GCC 4.0.1 (no OpenMP) and GCC 4.3.0
<li>Macintosh OSX 10.4 PowerMac with GCC 4.0.1 (no OpenMP)
<li>Cygwin under Windows XP i386 with GCC 3.4.4 (cygming special)
<li>SunOS 5.8 on an Ultra-1 sparc 64-bit with GCC 3.4.6 (no OpenMP)
</ul>
We don't know of any reason why kelvin shouldn't run on any platform supported by GNU CC and the GNU Scientific
Library, so if you encounter incompatabilities, please let us know.

<h4>Libraries</h4>
kelvin currently only requires the <a href="http://www.gnu.org/software/gsl/">GNU Scientific Library</a>
(GSL), a free numerical library for C and C++. This is already linked into the binary versions provided,
but if you want to build your own version, you will need to make a note of the location of the library and include
files on your system so that you can modify the kelvin Makefile.
<p>
When kelvin is run in polynomial mode, it makes very extensive use of memory management, and can, under most
circumstances, definitely benefit from a drop-in allocator such as <a href="http://www.hoard.org/">hoard</a>
or <a href="http://www.malloc.de/en/">ptmalloc3</a>. Either of these can easily halve execution time, and will
keep memory fragmentation down when running in multi-threaded mode, but they are not required. For more
details on using drop-in allocators with kelvin, see <a href="Allocators.html">the allocators section</a>.

<h4>Resources</h4>
kelvin's resource requirements vary widely depending upon the complexity of the analysis
being performed. In general, the memory requirements are negligible unless you use polynomial
mode (PE in the configuration file) to speed-up calculations. The idea of speeding-up calculations can become
quite attractive, as some seemingly simple analyses involve trillions of calculations and might
take months to run.
Polynomial mode can reduce
runtime by several orders of magnitude, but can also easily exceed 16Gb of memory for
complex pedigrees or those with untyped founders. The best approach is to normally use
polynomial mode, and fall back to non-polynomial mode if memory becomes an issue. Recent releases of kelvin
monitor CPU and memory utilization and will self-terminate if thrashing memory.
<p>
If you are running on a multi-core platform and your compiler supports 
OpenMP 2.0, you can build kelvin
to use multiple threads and reduce your single-analysis runtime significantly at a marginal increase in memory, less if
you use a drop-in allocator as described above.
<h3>Distribution</h3>
kelvin is developed in unix environments, so standard unix tools are used for build management and
distribution.
kelvin is currently distributed as a compressed tarball of the directory hierarchy of our
latest release, e.g. <tt>kelvin-0.34.2.tar.gz</tt>.
<h4>Directory Structure and Components</h4>
<ul>
<li><tt>&lt;RELEASE&gt;/</tt> - kelvin and calc_updated_ppl source components. Includes normal and debug versions of the master Makefile.
kelvin is the primary linkage analysis program and the focus of this documentation. dkelvin is a variant that
uses a multidimensional integration approach to analysis, and is still under development. calc_updated_ppl is
a tool for combining the results of an analysis broken into separate kelvin runs.
<li><tt>&lt;RELEASE&gt;/bin/</tt> - prebuilt kelvin binaries for different platforms. One of these may work for you.
<li><tt>&lt;RELEASE&gt;/doc/</tt> - (very) limited documentation, including these HTML files.
<li><tt>&lt;RELEASE&gt;include/</tt> - a work directory for builds.
<li><tt>&lt;RELEASE&gt;/lib/</tt> - a work directory for builds.
<li><tt>&lt;RELEASE&gt;pedlib/</tt> - pedigree, likelihood, and polynomial components. Includes a dependent Makefile - don't try
to use it by itself.
<li><tt>&lt;RELEASE&gt;/seq_update/</tt> - routines to perform a sequential update of the average likelihood ratios of separate
kelvin runs.
<li><tt>&lt;RELEASE&gt;/test-suite/</tt> - analyses that can be used for build validation as well as configuration examples.
<li><tt>&lt;RELEASE&gt;/utils/</tt> - general-purpose utility components. Includes a dependent Makefile.
</ul>
<p>
<h4 id="building">Building and Testing</h4>
If you cannot or do not wish to build a version of kelvin specific to your computing platform, 
you might be able to run one of the binary
versions provided in the distribution. Binary versions of kelvin are statically-linked executables
built without support for multi-threading. Version are provided for each of the environments for which we can build and test, and
are in the <tt>bin</tt> subdirectory of the distribution.
Simply copy the version you will be using to a directory on your PATH, and either name it kelvin or create
a link to it named kelvin.
<p>
If you are inclined to build your own version of kelvin, edit 
the master Makefile to specify the location of the gsl libraries and include files on your system.
<p>
There are a number of compilation conditionals that can be set in the Makefile to affect the behavior of kelvin.
These are disabled when commented-out with a pound-sign (#) at the start of the line, and enabled otherwise. Some
of the less useful diagnostic conditionals will not be covered here.
<ul>
<li><tt>-fopenmp</tt> Enables OpenMP multi-threading. This must be commented-out if your compiler does not
support OpenMP. This is enabled in the Makefile by default, but disabled in the prebuilt binaries. The number
of threads used is determined from the environment variable <tt>OMP_THREAD_COUNT</tt>. If this variable is not
set or is set to 0 (zero) the behavior depends upon the operating system, but typically the number of threads used
will correspond to the number of cores available. If <tt>OMP_THREAD_COUNT</tt> is set to 1 (one), then only a single
thread is used and it is as if OpenMP multi-threading is disabled. OpenMP multi-threading can greatly improve
polynomial evaluation, but at a moderate memory cost. The thread count should be less than the number of pedigrees 
in your analysis, up to the maximum of the number of cores on your platform. Monitoring user and system mode CPU
utilization with <tt>ps</tt> during polynomial evaluation will be your best indicator of the efficiency of threading
in your situation, and should guide you in selecting the right number of threads. Obviously you want the highest-
possible user-mode CPU utilization, but you need to watch out for increased system-mode CPU utilization, as it
is an indication that time is being wasted on thread synchronization, and that you probably have too many threads.
If OpenMP multi-threading support is built
into the binary, kelvin displays the thread count in a  diagnostic message on startup. 
<li><tt>SIMPLEPROGRESS</tt> Enables a simplified, but unfortunately non-linear percentage-completion display,
as opposed to a more detailed and more linear version. This is enabled by default.
<li><tt>MEMSTATUS</tt> Enables display of elapsed time and memory consumption every 30 seconds. Disabled by default.
<li><tt>MEMGRAPH</tt> Logs elapsed time and memory consumption to a file named <tt>kelvin_&lt;PID&gt;_memory.dat</tt>
every 30 seconds. This format can be graphed by <tt>gnuplot</tt> with a simple <tt>load "&lt;filename&gt;"</tt> command.
Disabled by default.
<li><tt>POLYSTATISTICS</tt> Enables a dump of extensive polynomial build statistics at every 2 million terms and
at build milestones. Disabled by default.
<li><tt>TREEEVALUATE</tt> Enables use of a polynomial evaluation technique that is optimal in situations where
polynomials are evaluated only a few times each. This is useful only in rare cases, and is disabled by default.
<li><tt>FAKEEVALUATE</tt> Does not do polynomial evaluation at all. This is used for exercise, evaluation, and
polynomial compilation. It will display a warning during compilation and when the program is run to the effect that
evaluation is disabled and result file data will be meaningless. This is disabled by default, and should only be
enabled with caution. It is documented here because an optimal performance strategy for analyses with extremely large
amounts of evaluation is to build compiled polynomials without evaluation on a single-core, large memory-
capacity machine, and then evaluate them on multi-core, smaller memory-capacity machines.
<li><tt>POLYUSE_DL</tt> Enables the use of dynamic libraries built for named polynomials should they be present in
the current default directory. Currently the only named polynomials implemented in kelvin are for
pedigrees, and these polynomials are specific to each marker set and relative trait position in the analysis. 
Compiled polynomials can be evaluated up to 10 times faster than internal polynomials, take up much less memory,
and do not need to be rebuilt in subsequent runs. A more detailed discussion of polynomial compilation is currently
under development. Disabled by default.
<li><tt>POLYCODE_DL</tt> Enables the writing of C source code implementing named polynomials when a previously-built
dynamic library for that polynomial has not been found. Disabled by default, requires POLYUSE_DL.
<li><tt>POLYCOMP_DL</tt> Enables the in-run compilation of any C source code written and the loading and use of the 
dynamic library built. Disabled by default, requires POLYCODE_DL.
<li><tt>POLYCHECK_DL</tt> Enables the comparison of evaluation results from any newly-built polynomial dynamic 
library with those of its source (internal) polynomial. Disabled by default, requires POLYCODE_DL.
</ul>
<p>
Once you have edited the Makefile to your satisfaction, type <kbd>make clean</kbd> and then <kbd>make</kbd>.
This should build supporting libraries and then the three executable images kelvin, dkelvin and calc_updated_ppl. 
<p>
Whether you use one of the prebuilt binaries or have built your own, it should be tested to
verify functionality. Type <kbd>make test</kbd> to run a suite of tests.
If you should see errors during the build or test, or run into other problems with kelvin,
please send us a log of the build and test.
<p>
Finally, if you built your own version, type <kbd>make install</kbd> to move it into production. 

<h2>PREPARING YOUR CONFIGURATION FILE</h2>
kelvin takes all of its configuration information from a single file specified on the command line.
This file is composed of directives that describe the analysis to be performed, and the locations
of supporting data files.
Extensive information on the directives used in the kelvin configuration file is provided in <tt>doc/ReadMe.conf</tt>.
It is the final authority on the behavior of the directives, and the only source of information on the
specification of
parameters and ranges. A <a href="Directives.html">rewrite</a> of that document is in-progress.
<p>
kelvin provides such a wide variety of options for linkage analysis that it can be confusing to
determine what combinations of directives are appropriate. The following chart shows kelvin features and options.
<p>
<table border="1">
<tr>
<th colspan=3>Features and Options</th>
<tr>
<th>Marker/Map</th>
<th>Phenotypes</th>
<th>Genetic Model</th>
<tr>
<td>
<ul>
<li>multipoint (MP) or two point (2pt)
<li>marker-to-marker LD (2pt only)
<li>haldane or kosambi scale
<li>sex-specific or averaged (MP only)
</ul>
</td>
<td>
<ul>
<li>dichotomous trait (DT)
<li>quantitative trait (QT)
<li>QT with threshold
<li>right/left truncated QT model (not tested)
</ul>
</td>
<td>
<ul>
<li>parent-of-origin dependent penetrance
<li>multiple liability classes
<li>trait-to-marker LD (2pt only)
</ul>
</td>
</table>
<p>
<a href="config.gif">Here is a directed graph</a> illustrating the legitimate combinations of features
and options. It illustrates the twenty-two current configuration "paths" for kelvin, and the directives 
they use. Ovals
represent defaults that will be taken in the absence of relevant directives, while squares represent
analysis attributes that must always be explicity specified.
<p>
The distribution includes subdirectories with sample configuration files for a few of
the configuration "paths". We typically name the configuration files <tt>kelvin.conf</tt>.
These illustrate the required configuration information, and can serve as starting points for your own
versions. Unless otherwise noted, we have externally verified the results of analysis for these tests,
and they are provided in each directory in <tt>br.out-baseline</tt> and (as appropriate) 
<tt>ppl.out-baseline</tt>. The runtimes
listed are on an Macintosh OSX 10.4 i386 with GCC 4.0.1 (no OpenMP).
<ul>
<li>Two-point analysis of a dichotomous trait: <tt>&lt;RELEASE&gt;/test-suite/PE/TP_DT_LE/</tt>, runs in 53s.
<li>Two-point analysis of a dichotomous trait with linkage disequilibrium: <tt>&lt;RELEASE&gt;/test-suite/PE/TP_DT_LD/</tt>, runs in 1m 43s.
<li>Two-point marker-to-marker analysis: <tt>&lt;RELEASE&gt;/test-suite/PE/TP_DT_MM_LE/</tt>, 
runs in less than 1s with a minor deviation (1 in 7th position) in one bayes ratio value from runs on other
platforms. This sort of deviation in test results is attributable to the different C and gsl libraries used on
different platforms.
<li>Two-point analysis of a dichotomous trait going marker-to-marker with linkage disequilibrium: <tt>&lt;RELEASE&gt;/test-suite/PE/TP_DT_MM_LD/</tt>, runs in less than 1s.
<li>Two-point analysis of a quantitative trait: <tt>&lt;RELEASE&gt;/test-suite/PE/TP_QT_LE/</tt>, runs in 26s.
<li>Sex-averaged multipoint analysis of a dichotomous trait: <tt>&lt;RELEASE&gt;/test-suite/PE/SA_DT/</tt>, runs in 2s.
<li>Sex-averaged multipoint analysis of a quantitative trait: <tt>&lt;RELEASE&gt;/test-suite/PE/SA_QT/</tt>, runs in 1s.
<li>Two liability class version of sex-averaged multipoint analysis of a quantitative trait: <tt>&lt;RELEASE&gt;/test-suite/PE/SA_QT_LC2/</tt>, runs in 3m 40s.
</ul>

<h2>RUNNING THE PROGRAMS</h2>
Once you have installed kelvin, you can run it from your data directory, where you keep your
configuration and data files. kelvin takes only one parameter, which is the name of the
configuration file, e.g.:

<pre>
_$ kelvin kelvin.conf
</pre>
Remember that if you did not specify absolute paths for output files in the configuration file, they
will be written relative to your current directory.
<p>
It is often convenient to capture all output from a run into a file so that you may review it more
conveniently, or send it to us for diagnosis. The following command (using bash shell syntax)
runs kelvin with all output
redirected to a file called <tt>kelvin.out</tt>:
<pre>
_$ kelvin kelvin.conf >& kelvin.out
</pre>
If you do need to send us information for diagnosis, please include the configuration and data files
along with the output from the run.
<h3>Diagnostic Messages</h3>
When kelvin or dkelvin are run, they first display version, build and run configuration information, e.g.:
<pre>
PID: 3072, kelvin V0.34.2 built May 29 2008 10:06:56
PID: 3072, Id: kelvin.c 579 2008-06-03 13:28:20Z whv001
PID: 3072, Id: likelihood.c 533 2008-05-23 17:26:34Z whv001
PID: 3072, Id: locus.c 471 2008-05-06 20:17:17Z whv001
PID: 3072, Id: polynomial.c 570 2008-06-02 19:28:31Z whv001
PID: 3072, Compiler 4.1.1 20070105 (Red Hat 4.1.1-52), GSL 1.9
PID: 3072, OpenMP-enabled w/0 threads.
To force a dump of stats (at some risk), type CTRL-\ or type "kill -3 3072".
PID: 3072, In /Users/whv001/kelvin/trunk/test-suite/MP_DT w/kelvin.conf
polynomialScale is 1 (1-10, 1 is default)
PID: 3072, Computation is done in polynomial mode

</pre>
The first line is the kelvin major version and build information, and the subsequent lines
that contain "Id:" are source-managed component version information. Next is the compiler
and GNU Scientific Library verison numbers. Lines after that
describe important compilation conditionals as specified in the Makefile and run
characteristics as influenced by environment variables. In the example given, OpenMP support
status and the number of threads used (0 selects the platform-specific default number of threads)
is displayed. Other options and their corresponding messages are covered in the <a href="#building">
Building and Testing</a> section.
<p>
In the midst of this is a line describing the action to take in order to force a dump of a line of
statistics. The format of these statistics is described at the end of the next subsection (<a href="#adhoc">ad hoc status</a>).
You can use this as a sort of "pulse check" to make sure kelvin is still alive
and well and making progress should there be a lull between automatic progress updates. If
you are running kelvin interactively, you can type <tt>CTRL-\</tt> (that means to hold down the CTRL
or CONTROL key while pressing the backslash). If you are running under cygwin, you will need to
type <tt>stty quit ^C</tt> first for this to work. Strangely enough, that <tt>^C</tt> is the two
character sequence of 'carat' (shifted 6) and 'C'. <tt>CTRL-\</tt> sends a SIGQUIT signal to kelvin, which it
interprets as a request for status. If you are running kelvin as a detached
process or in a batch queue, you can send a SIGQUIT to the process by being logged-into the same
node as it is running on, and using the <tt>kill</tt> command
as described in the diagnostic output. Note that the signal number (-3 in the example) can be
different from platform-to-platform, and the
process ID (3072 in the example) will be different from run-to-run.
<p>
Next, the analysis characteristics as determined from the configuration and data files
are displayed, e.g.:
<pre>
Trait-to-marker, Sex-Averaged Multipoint (3 loci at a time), Dichotomous Trait.
</pre>
Finally, progress indicators are displayed up through the end of the run.

<h3>Monitoring Progress</h3>
There are two levels of detail of progress information for you to choose from. The default is to simply display
a rough percentage of work completed and a wobbly estimate of how many minutes of work remain. These
numbers can become extremely rough and wobbly in polynomial evaluation mode, because few aspects of the complex operations
they must consider can be accurately estimated, even while they're in-progress. Progress reporting will be most
accurate and useful when you are doing many evaluations of simple pedigrees.
<p>
You need not take any special action in order for progress to be displayed in this manner:
<pre>
Calculations 18% complete (~15 min left)
</pre>
While the simple progress display incorporates trait and marker calculations and polynomial builds in its estimations, it doesn't report
progress while they're being performed, so there might be a significant delay before seeing the first non-zero percentage for complex
analyses, and during polynomial builds.
<p>
The alternative level of complexity is much more informative, but can overwhelm with details under certain
circumstances. You will need to edit the <tt>Makefile</tt> to disable the compile-time conditional
<tt>SIMPLEPROGRESS</tt>, and rebuild kelvin (<tt>make clean</tt> and <tt>make</tt>) to turn it on. When 
<tt>SIMPLEPROGRESS</tt> is disabled, kelvin displays
detailed information about each of the steps it goes thru to perform an analysis. These steps are
fundamentally different for Two-Point and Multipoint analyses.

<h4>Detailed Multipoint Displays</h4>
<ol>
<li>Trait likelihood determination progress in percentage until completion. This is only done once
at the beginning of an analysis, so it will proceed to 100%. This is the simplest and therefore fastest
calculation. If this step takes a lot of time, subsequent steps may not complete in a reasonable timeframe.
<pre>
Determining trait likelihood...
Building polynomial w/pedigree: 87 (11/11)
Trait likelihood evaluations 100% complete
</pre>
<li>For each trait position:
<ol>
<li>The new trait position, and the markers to be used in this step of the analysis along with their positions if they are new:
<pre>
Starting w/trait locus at 0.00 (1/8 positions) with new markers 1(0.00) 2(0.64)
Determining marker set likelihood...
</pre>
or if they are the same:
<pre>
Starting w/trait locus at 0.50 (2/8 positions) with same markers.
Determining combined likelihood...
</pre>
<li>Likelihood polynomial build progress when there are new markers. This is shown as progress thru the set of
pedigrees, and is a function of the pedigree complexity and number of markers in the analysis. 
This cannot be reliably estimated at this time, but is typically one of the less time-consuming steps:
<pre>
Building polynomial w/pedigree: 77 (1/11)
</pre>
<li>Marker likelihood evaluation progress when there are new markers. This is displayed as an incrementing percentage 
until it is interrupted by the completion of the current position. At completion of a position it will reflect 
overall percentage progress of marker likelihood evaluation thru all positions. This may jump because 
we skip marker likelihood evaluation when the marker set does not change in relation to the trait position:
<pre>
Marker set likelihood evaluations 12% complete.
Determining combined likelihood...
</pre>
<li>Combined likelihood polynomial build progress when there are new markers. This is shown as progress thru the set of pedigrees. This is
the most memory-intensive step, and can be very time-consuming as well. Unfortunately, it is nearly completely unpredictable
across trait positions, as it is a function of phenotypic and genotypic constraints for the trait and markers thru
the pedigrees. If your analysis is going to fail due to lack of memory, it will be here. You can anticipate problem 
pedigrees by noting those that took longer than average during
the marker set likelihood polynomial build phase. Accurate estimation would almost require performing the analysis before performing the analysis.
The good news is that evaluation is radically improved by having the polynomial, so if you are analyzing a grid of
penetrances, disease gene frequencies and alpha values, polynomial mode will be much faster.
<pre>
Building polynomial w/pedigree: 87 (11/11)
</pre>
<li>Combined likelihood evaluation progress. This is displays every minute until completion for this position. Note
that the estimation of time remaining can oscillate significantly, so don't use it as a timer when you're baking cookies.
<pre>
Combined likelihood evaluations 1% complete (~83 minutes left)
</pre>
</ol>
</ol>
If polynomial evaluation is not enabled, the progress reports involving polynomials are not displayed.
<h4>Detailed Two-point and Marker-to-Marker Displays</h4>
<ol>
<li>The names of the pair of loci to be used in this step of the analysis:
<pre>
Starting w/loci Disease and Locus_7 at 0.00 (1/8 pairs)
</pre>
<li>Likelihood polynomial build progress. This is shown as progress thru the set of
pedigrees, and is a function of the pedigree complexity. This cannot be reliably estimated 
at this time, but is one of the less time-consuming steps:
<pre>
Building polynomial w/pedigree: 77 (1/11)
</pre>
<li>Likelihood evaluation progress. This is displayed as an incrementing percentage 
until it is interrupted by the completion for the current pair of loci. At completion of a pair it will reflect 
overall percentage progress of likelihood evaluation thru the entire analysis.
<pre>
Calculations 12% complete (~15 min left)
</pre>
</ol>
</ol>
If polynomial evaluation is not enabled, the progress reports involving polynomials are not displayed.

<h4 id="adhoc">Final (and Ad Hoc) Status</h4>
Under either level of complexity, a line of statistics will be displayed at the end of the run that looks
something like this:
<pre>
PID: 3072, stopwatch overall(1) e:462s u:460s s:1s, vx:0, ivx:0, sf:0, hf:0
</pre>
This is a dump of the current values of a virtual stopwatch that was started at the beginning of the analysis.
Of greatest interest are the elapsed time in seconds (<tt>e:462</tt> in the example) and the user CPU time used in seconds
(<tt>u:460</tt>), which can be lower or higher than the elapsed time depending upon if kelvin is competing with
other processes for CPU time or if it is efficiently using multiple threads. The system CPU time (<tt>s:1s</tt>) is also
provided along with some other statistics (voluntary context switches, involuntary context switches, soft faults
and hard faults) that may or may not be available on your platform.
<h4>Additional Options</h4>
There are a number of additional progress reports that can be monitored during a run using compile-time
conditionals. You will need to edit the <tt>Makefile</tt> and rebuild kelvin (<tt>make clean</tt> and <tt>make</tt>) to turn them on
or off:
<ol>
<li><tt>MEMSTATUS</tt> conditional - When kelvin or dkelvin are run on compatible platforms (currently only those with a pmap command),
a child process is created that monitors elapsed time and memory utilization, and displays it every 30 seconds.
<li><tt>POLYSTATISTICS</tt> conditional - If polynomial evaluation is enabled:
<ul>
<li>a count of evaluations peformed thus-far is displayed every 64K evaluations.
<li>extensive statistics on the polynomial build process are displayed
every 2M polynomial creations, when polynomial builds finish, and at the end of the run. Statistics will
include an estimation of internal memory usage when feasible and relevant.
</ul>
</ol>
<h2>INTERPRETING THE RESULTS</h2>
kelvin produces several different files of results depending upon the type of analysis performed.
<h3>Bayes Ratio File</h3>
Integrated likelihood ratio (BR) information is produced for all runs. It is written to the file specified by
the <tt>HE</tt> directive, or <tt>br.out</tt> by default.
The first line written to the file is a comment that contains the kelvin version number, e.g.:
<pre>
# kelvin V0.34.2 built May 29 2008 10:06:56
</pre>
This is included so that results can be associated with the version of kelvin that
produced them, and will allow for variations in algorithms, file formats and data precision.
Subsequent lines contain different information for each type of analysis being performed:
<h4>Multipoint Analysis</h4>
For multipoint runs, a single table with a header line is output. 
The table consists of one row for each trait position with bayes ratio information for
the position,
and the values for alpha, disease gene frequency and penetrance that maximized the LOD at the
position. Columns are whitespace-delimited:
<ol>
<li>Chr - chromosome number
<li>Position - trait positions in centiMorgans
<li>PPL - the posterior probability of linkage. This is rounded to two places if .025 or
greater, and three decimal places otherwise.
<li>BayesRatio - integrated likelihood ratio.
<li>MOD - maximum HLOD score achieved at this position.
<li>Alpha - the maximizing alpha, i.e. the value of alpha that maximized the HLOD score. 
<li>DGF - the maximizing disease gene frequency, i.e. the frequency that maximized the HLOD score.
<li>LC<tt>n</tt>PV(...) - penetrance vector, one for each liability class in the analysis. 
For dichotomous trait runs, it is three (or four) columns of 
the maximizing penetrance for
DD, Dd, (optionally dD,) and dd, i.e. the penetrance that maximized the HLOD score.
For quantitative trait (QT) runs with normal or Student's-T distributions,
it is three (or four) columns of means followed by three 
(or four) of standard deviations for
the maximizing distributions for DD, Dd, (optionally dD,) and dd, followed by the threshold
in the case of the QT threshold model. Quantitative
trait runs with the Chi-Square distribution  have only three (or four) columns of degrees of freedom followed
by the threshold. Values are
comma-separated and enclosed in parentheses. Header text reflects actual count and nature of columns.
<li>MarkerList(...) - parenthesised list of the closest N markers for each position, where N is the number
of markers being considered at a time. Header text reflects actual count of columns.
</ol>
<h4>Two-point and Marker-to-Marker Analysis</h4>
Two-point analyses output separate tables for each pair of adjacent loci. For marker-to-marker runs,
this is each pair of adjacent markers. For marker-to-trait runs, this is the disease locus with each marker.
Each table is prefaced with a comment line that specifies the two loci of interest, e.g.:
<pre>
# 2  Loci_1 at (location) Loci_3 at (location)
</pre>
and consists of one row of whitespace-delimited values for each value of D' (d-prime) if this is an
LD analysis, theta, integrated likelihood information, and the values for alpha, disease gene frequency and
penetrance that maximized the HLOD for this D' and theta.
<ol>
<li>Chr - chromosome number
<li>multiple columns of D<i>nm</i> - the D' (d-prime) between allele <i>m</i> of the first locus and allele <i>n</i> of the
second locus. There will be (<i>n</i>-1)*(<i>m</i>-1) columns present for linkage disequilibrium runs. These
columns are not present on LE runs because
LE is a special case of LD where D' is always 0.
<li>Theta(M,F) - male and female theta values. They are identical for a sex-averaged analysis.
<li>BayesRatio - integrated likelihood ratio.
<li>MOD - maximum HLOD score achieved for these loci at these values of D' (if LD) and theta.
<li>R2 - R square, an alternative measurement of LD.
<li>Alpha - the maximizing alpha, i.e. the value of alpha that maximized the HLOD score.
<li>DGF - the maximizing disease gene frequency, i.e. the frequency that maximized the HLOD score.
<li>MF - marker allele frequency for the first marker.
<li>LC<tt>n</tt>PV(...) - penetrance vector, one for each liability class in the analysis. 
For dichotomous trait runs, it is three (or four) columns of 
the maximizing penetrance for
DD, Dd, (optionally dD,) and dd, i.e. the penetrance that maximized the HLOD score.
For quantitative trait runs with normal or Student's-T distributions,
it is three (or four) columns of means followed by three 
(or four) of standard deviations for
the maximizing distributions for DD, Dd, (optionally dD,) and dd, followed by the threshold, if applicable. 
Quantitative
trait runs with the Chi-Square distribution  have only three (or four) columns of degrees of freedom followed
by the threshold. Values are
comma-separated and enclosed in parentheses. Header text reflects actual count and nature of columns.
</ol>
<h3>Posterior Probability of Linkage (PPL) File</h3>
Separate PPL information is produced for two-point analyses.
It is written to the file specified by the <tt>PF</tt> directive, or <tt>ppl.out</tt> by default.
The first line is a comment that contains the kelvin version number as with the Bayes Ratio file.
The next line is a header, followed by
one line of whitespace-delimited values for each marker in the run.
<ol>
<li>Chr - chromosome number
<li>Marker - marker name
<li>Position - position in centiMorgans
<li>PPL - posterior probability of linkage. Evidence for or against linkage to the disease 
locus, not allowing for disequilibrium, i.e.
D' is fixed at 0.  It is rounded to two places if .025 or
greater, and three decimal places otherwise.
<li>LD-PPL (only for LD analyses) - evidence for or against linkage allowing disequilibrium, i.e.
D' can range from -1 to 1. It is rounded to two places if .025 or
greater, and three decimal places otherwise.
<li>PPLD (only for LD analyses) - posterior probability of linkage disequilibrium, a measure of
LD. It is rounded to two places if .025 or
greater, and three decimal places otherwise.
</ol>
<h3>Two-Point Maximizing Models (TP) File</h3>
A file describing the maximizing model parameters for each pair of loci is
produced for two-point analyses. It is written to the file specified by the <tt>MX</tt> directive,
or <tt>tp.out</tt> by default. This file is currently being brought into compliance with our
standards, so column layout and naming will change.
For each pair of loci, it displays maximizing information for each of:
<ol>
<li>Overall MOD maximizing model
<li>MOD maximizing model for theta=0
<li>MOD maximizing model for dprime=0
<li>Overall LR maximizing model
<li>LR maximizing model for theta=0
<li>LR maximizing model for dprime=0
</ol>
The maximizing values are provided under the following column headings:
<ol>
<li>Chr - chromosome number
<li>Marker - marker name
<li>Position - position in centiMorgans
<li>MOD - maximum HLOD score achieved for these loci at these values of D' (if LD) and theta
<li>DPrime - maximizing D'
<li>Theta
<li>R2
<li>ALPHA
<li>DGF
<li>MF
<li>PEN_DD PEN_Dd PEN_dd
</ol>

<h2>SEQUENTIAL UPDATING</h2>
Sequential updating is a method for combining the results of mutiple analyses in post-processing.
Three tools are provided for performing sequential updating. All tools expect kelvin Bayes
Ratio files as input.

<h3>seq_update_br.pl</h3>

This Perl script will perform sequential updates on either two-point or multi-point files.
The default is two-point. Multi-point may be specified by passing <tt>-m multipoint</tt> on
the command line. Bayes Ratio files must be in the most recent format. Older formats can be
converted using <tt>convert_br.pl</tt> (see below). The script will generate output that
resembles the input, but will fill non-relevant columns (maximizing models, alphas, etc.)
with zeros. Multiple input files may be specified on the command line. In two-point mode,
all files should contain information for the same markers, in the same order. If
<tt>--relax</tt> is specified, marker name checking will be skipped, but there should
still be the same number of markers in each file. In multi-point mode, there should be
information for the same number of positions in every file. In multi-point mode only, the
new PPL will be calculated directly, based on the updated Bayes ratios. New PPLs can
be generated for two-point Bayes ratios using <tt>calc_updated_ppl</tt> (see below).
Output is always to the terminal. Here's an example of updating across three multipoint
files that captures the output to a file:

<pre>
_$ seq_update_br.pl -m multipoint br-1.out br-2.out br-3.out > updated-br.out
</pre>

A full description of command line syntax is available by typing:

<pre>
_$ seq_update_br.pl --help
</pre>

<h3>convert_br.pl</h3>

This Perl script will convert <tt>avghet.out</tt> or <tt>br.out</tt> files generated by
older versions of kelvin into the most recent format. If the file is old enough that it
does not contain a column identifying the chromosome, one will need to be specified
on the command line with the <tt>-c <i>chrnum</i></tt> flag. Output is always to the 
terminal. Here's an example that captures the output to a file:

<pre>
_$ convert_br.pl -c 12 avghet-old.out > br-new.out
</pre>

Note in this example, <tt>-c 12</tt> specifies that <tt>avghet-old.out</tt> contains
data from an analysis of chromosome 12.

<h3>calc_updated_ppl</h3>

This program will calculate PPL, LD-PPL and PPL scores based on a two-point kelvin Bayes
Ratio file, or the output from seq_update_br.pl. It handles multi-allele (multiple
D's) and sex-specific thetas. It takes only one argument, the name of the input file. Output
is alway to the terminal. Here's an example that, again, captures the output to a file:

<pre>
_$ calc_updated_ppl updated-br.out > updated-ppl.out
</pre>
<hr>
$Date$
</body>

</html>
